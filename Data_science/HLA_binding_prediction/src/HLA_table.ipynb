{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import Bio\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section is for table reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "root = os.getcwd()\n",
    "data = root + '/affinity_data.csv'\n",
    "peptide_file = root + '/binding_peptides.fas'\n",
    "HLA_file = root + '/HLA_aln.fas'\n",
    "\n",
    "def to_number(s):\n",
    "    try:\n",
    "        s1 = float(s)\n",
    "        return s1\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional block for data manipulation\n",
    "\n",
    "#data_ref = root+'/affinity_data_refined.csv'\n",
    "#df = df.replace('-', 50000)\n",
    "#res = df.applymap(lambda x: to_number(x))\n",
    "#res['DPB1:04:01'][0]\n",
    "#df.to_csv(data_ref,sep=',', mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data, index_col=0)\n",
    "data_matrix = df.as_matrix()\n",
    "df.stack().hist(color='k', alpha=0.5, bins=100)\n",
    "plt.show()\n",
    "Y_dist_tmp = [i for i in list(data_matrix.flatten().astype(int)) if i < 50000]\n",
    "Y_dist = np.array(Y_dist_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-523-e45e78ce2ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#r = stats.poisson(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#r = stats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpylab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import poisson\n",
    "\n",
    "#expon_example = np.random.exponential(scale=50000, size=17000)\n",
    "#measurements = np.where(expon_example >= 50000)[0]\n",
    "\n",
    "stats.probplot(Y_dist, dist=\"norm\", plot=pylab)\n",
    "#r = stats.poisson.rvs(1.5)\n",
    "#r = expon.ppf([0.001, 0.5, 0.999])\n",
    "#r = stats.poisson(2)\n",
    "#r = stats.\n",
    "stats.probplot(Y_dist, dist=r, plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Dict HLA-peptide IC50: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NestedDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        self[key] = type(self)()\n",
    "        return self[key]\n",
    "\n",
    "affinity = NestedDict()     \n",
    "df = pd.read_csv(data, index_col=0)\n",
    "for k,v in df.stack().iteritems():\n",
    "    affinity[k[0]][k[1]] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HQI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from encode_HQI8 import *\n",
    "from Bio import SeqIO\n",
    "import itertools\n",
    "\n",
    "'''\n",
    "#Itertools chaining example: \n",
    "a = [[1,2,3],[4,5,6]]\n",
    "list(itertools.chain(*a))\n",
    "'''\n",
    "\n",
    "def encode_seq(entry):\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    aaindex = list(itertools.chain(*tmp))    \n",
    "    return aaindex\n",
    "\n",
    "# This operation normalize the data \n",
    "def encode_seq_norm(entry, max_vals, min_vals):\n",
    "    delta = max_vals - min_vals\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    vals = list(itertools.chain(*[list((t - min_vals)/delta) for t in tmp]))\n",
    "    return vals\n",
    "    \n",
    "def min_max(entry):\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    max_vals = np.amax(tmp, axis=0)\n",
    "    min_vals = np.amin(tmp, axis=0)\n",
    "    return max_vals, min_vals\n",
    "\n",
    "#res_1 = encode_seq('MASSSSVLLVVVLFA')\n",
    "#res_2 = encode_seq_norm('MASSSSVLLVVVLFA', max_vals, min_vals)\n",
    "#print res_1\n",
    "#print res_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(entries):\n",
    "    max_vals, min_vals = min_max('GAVLIPFYWSTCMNQKRHDE')\n",
    "    feature_dict = {}\n",
    "    for e in entries[0:]:\n",
    "        feature_dict[e.id] = encode_seq(e.seq)                         # Not-normalized data\n",
    "        #feature_dict[e.id] = encode_seq_norm(e.seq, max_vals, min_vals) # Normalized data\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peptide features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "peptides = list(SeqIO.parse(peptide_file, 'fasta'))\n",
    "pep_dict = featurize(peptides)\n",
    "#pep_dict\n",
    "\n",
    "rec_test = SeqRecord(Seq(''.join('Q'), IUPAC.protein), id='id')\n",
    "#featurize([rec_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### HLA descriptors' features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRB1*01_01 WLFECSDLQRAY\n",
      "DPB1*02_01 FGQEYFDIEEVM\n",
      "DQB1*02_01 YFGSSIAIRKAV\n",
      "DRB1*07_01 WGYELFVIDRQV\n",
      "DRB1*09_01 KDFHGNVFRREV\n",
      "DRB3*01_01 ERSDYFVLQKRY\n",
      "DRB3*02_02 ELSEHYDLQKQY\n",
      "DRB1*11_01 ESSDYYDFDRAY\n",
      "DRB1*13_02 ESSDYNDIDEAY\n",
      "DRB1*03_01 ESSDYNDLQKRY\n",
      "DRB1*12_01 ESGEHLVIDRAY\n",
      "DRB1*08_02 ESGDYYDFDRLY\n",
      "DRB1*04_01 EVHDYYDLQKAY\n",
      "DRB1*04_05 EVHDYYSLQRAY\n",
      "DRB1*15_01 WPRDYSDIQAAY\n",
      "DRB5*01_01 QDYHDDDFDRAY\n",
      "DRB4*01_01 EACIYYDLRREY\n",
      "DQB1*03_01 YFATYYDVRTEV\n",
      "DQB1*03_02 YFGTYYAVRTEV\n",
      "DQB1*04_01 FFGTYYDIEDSV\n",
      "DQB1*05_01 YFGTHYVVGASV\n",
      "DQB1*06_02 FFGTYYDVGTEV\n",
      "DPB1*05_01 FGQEYLEIEKVM\n",
      "DPB1*14_01 HLQEYFDLEKVV\n",
      "DPB1*01_01 YGQEYYAIEKVV\n",
      "DPB1*04_02 FGQEYFDIEKVM\n",
      "DPB1*04_01 FGQEYFAIEKVM\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "HLAs = list(SeqIO.parse(HLA_file, 'fasta'))\n",
    "HLA_desc = OrderedDict([\n",
    "                        ('b9', 40),\n",
    "                        ('b11', 42),\n",
    "                        ('b13', 44),\n",
    "                        ('b28', 59),\n",
    "                        ('b30', 61),\n",
    "                        ('b37', 68),\n",
    "                        #('b47', 78), # Y or W\n",
    "                        ('b57', 88),\n",
    "                        #('b60', 91), # constant\n",
    "                        #('b61', 92), # constant\n",
    "                        ('b67', 98),\n",
    "                        ('b70', 101), # *\n",
    "                        ('b71', 102), # *\n",
    "                        ('b74', 105), # *\n",
    "                        ('b78', 109), # *\n",
    "                        #('b81', 112), # almost constant\n",
    "                        #('b82', 113), # almost constant\n",
    "                        #('b85', 116), # almost constant\n",
    "                    ])\n",
    "\n",
    "def make_SeqRecord(HLAs, HLA_desc):\n",
    "    HLA_list = []\n",
    "    for h in HLAs:\n",
    "        #print h.id, h.seq[HLA_descriptors['b9']], h.seq[HLA_descriptors['b11']], h.seq[HLA_descriptors['b13']]\n",
    "        sele = [h.seq[i] for i in HLA_desc.values()]\n",
    "        #print h.id, ''.join(sele)\n",
    "        record = SeqRecord(Seq(''.join(sele),\n",
    "                   IUPAC.protein),\n",
    "                   id=h.id)\n",
    "        HLA_list.append(record)\n",
    "    return featurize(HLA_list)\n",
    "\n",
    "    \n",
    "HLAs_dict = make_SeqRecord(HLAs, HLA_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section allows to prepare the data for the regression analysis, without reading it from external files.\n",
    "This allows to easly modify the features used in the regression procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_len = len(HLA_desc) * len(HQI8_descriptors) + 15 * len(HQI8_descriptors)\n",
    "features_count = ['f'+ str(i) for i in range(1,features_len+1)]\n",
    "features_count.insert(0,'HLA')\n",
    "features_count.insert(0,'peptide')\n",
    "features_count.append('IC50')\n",
    "\n",
    "def get_xy():\n",
    "    tmp_list = []\n",
    "\n",
    "    # Iterates over the elements within the 2-level dict\n",
    "    for k1,v1 in affinity.iteritems():\n",
    "        for k2,v2 in v1.iteritems():\n",
    "            tmp_i = list(itertools.chain(*[list([k1]), list([k2]), pep_dict[k1], HLAs_dict[k2], list([int(v2)])]))\n",
    "            tmp_list.append(tmp_i)\n",
    "            #list_y.append(y_i)\n",
    "\n",
    "    return np.array(tmp_list)#, np.array(list_y)\n",
    "\n",
    "df = pd.DataFrame(get_xy(), columns=features_count)\n",
    "\n",
    "# Type checking\n",
    "df[features_count[2:-1]] = df[features_count[2:-1]].astype(np.float32) # This changes all features into floats\n",
    "df['IC50'] = df['IC50'].astype(np.integer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining HLA/peptide features with affinity value into new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fo = open('dataset_norm_v2.csv', 'a+')\n",
    "features_len = len(HLA_desc) * len(HQI8_descriptors) + 15 * len(HQI8_descriptors)\n",
    "features_count = ['f'+ str(i) for i in range(1,features_len+1)]\n",
    "header = 'id,peptide,HLA,' + ','.join(str(x) for x in features_count) + ',IC50\\n'\n",
    "fo.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterates over the elements within the 2-level dict\n",
    "i=1\n",
    "for k,v in affinity.iteritems():\n",
    "    for k1,v1 in v.iteritems():\n",
    "        features = list(itertools.chain(*[pep_dict[k], HLAs_dict[k1]]))\n",
    "        #message = k + '\\t' + k1 + '\\t' + ','.join(str(x) for x in features) + '\\t' + str(v1) + '\\n'\n",
    "        #message = k + '_' + k1 + ',' + ','.join(str(x) for x in features) + ',' + str(v1) + '\\n'\n",
    "        message = str(i) + ',' + k + ',' + k1 + ',' +','.join(str(x) for x in features) + ',' + str(v1) + '\\n'\n",
    "        fo.write(message)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Just in case you want to read the file\n",
    "#df = pd.read_csv('../dataset/dataset_norm_v2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data -> X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filter data y>0, y<50000\n",
    "#df = df[df.IC50 > 0]\n",
    "#df = df[df.IC50 < 50000]\n",
    "df = df[~((df.IC50 < 0) & (df.IC50 > 50000))]\n",
    "df = df.reset_index(drop=True) # Important for re-indexing \n",
    "\n",
    "\n",
    "#Generate Training and testing \n",
    "def train_test(df, perc):\n",
    "    sele = []\n",
    "    while len(sele) <= int(len(df) * perc):\n",
    "        sele.append(np.random.randint(len(df)))\n",
    "        sele = list(set(sele))\n",
    "    \n",
    "    X_test = df.ix[sele]\n",
    "    y_test = df.IC50[sele]\n",
    "    X_train = df.drop(df.index[sele])\n",
    "    y_train = df.IC50.drop(df.index[sele])\n",
    "    \n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    \n",
    "    X_test = X_test.drop(['IC50','peptide','HLA'], axis=1)\n",
    "    X_train = X_train.drop(['IC50','peptide','HLA'], axis=1)\n",
    "\n",
    "    # We initially transform the data into \n",
    "    #X = X_df.as_matrix()\n",
    "    #y = y_df.as_matrix()\n",
    "    #target_names = X_df.columns.values\n",
    "    return X_test.as_matrix(), y_test.as_matrix(), X_train.as_matrix(), y_train.as_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Itertools chaining example: \n",
      "a = [[1,2,3],[4,5,6]]\n",
      "list(itertools.chain(*a))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "n_comp = 250\n",
    "pca = PCA(n_components=n_comp)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "#print('explained variance ratio (first %s components): \\n %s') %(n_comp, str(pca.explained_variance_ratio_))\n",
    "eigenv = pca.explained_variance_ratio_\n",
    "plt.bar (range(len(eigenv)), eigenv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-699-e91bfbde1192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#f_select = sklearn.feature_selection.f_regression(X_train, y_train, center=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#f_select\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-648-85b89c9546e7>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(df, perc)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msele\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mperc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msele\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msele\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#f_select = sklearn.feature_selection.f_regression(X_train, y_train, center=True)\n",
    "#f_select\n",
    "X_test, y_test, X_train, y_train =  train_test(df, 1)\n",
    "transform(X_train, threshold=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "feat_zip = zip(f_select[1], list(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = [1,4,3,2]\n",
    "#b = ['a','d','c','b']\n",
    "#[(x,y) for (y,x) in sorted(zip(a,b))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_select' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e8a582133894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# AA importance rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_select' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def feat_seed(num):\n",
    "    res = math.floor((num - 0.1)/4) + 1\n",
    "    return int(res)\n",
    "\n",
    "test_dict = {}\n",
    "feat_importance = [(x,y) for (y,x) in sorted(zip(f_select[1],list(target_names)))]\n",
    "feats = [str(feat_seed(int(x[1:]))) for (y,x) in sorted(zip(f_select[1],list(target_names)))] # AA importance rank\n",
    "points = list(reversed(range(1, len(feats)+1)))\n",
    "feat_points = zip(feats, points)\n",
    "\n",
    "feat_points\n",
    "for i in feat_points:\n",
    "    if test_dict[i[0]]:\n",
    "        test_dict[i[0]] = test_dict[i[0]] + i[1]\n",
    "    else:\n",
    "        test_dict[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regression Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training points: 15454, Testing points: 1718\n",
      "0.329936621521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "params = {\n",
    "            'perc': 0.1,\n",
    "            'n_estimators' : 10,\n",
    "            'max_features': \"sqrt\",\n",
    "            'n_jobs' : -1\n",
    "        }\n",
    "    \n",
    "def regressor(params):\n",
    "    X_test, y_test, X_train, y_train =  train_test(df, params['perc'])\n",
    "    print \"Training points: %s, Testing points: %s\" %(len(y_train), len(y_test))\n",
    "    estimator = RandomForestRegressor(random_state=0, n_estimators=params['n_estimators'], n_jobs=params['n_jobs'])\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_estimated = estimator.predict(X_test)\n",
    "    score = r2_score(y_test, y_estimated, sample_weight=None)\n",
    "    return score, y_test, y_estimated\n",
    "\n",
    "score, y_test, y_estimated = regressor(params)\n",
    "residuals = y_test - y_estimated\n",
    "print score\n",
    "#estimator.score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Residuals distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "#plt.hist(data, bins=np.arange(min(data), max(data) + binwidth, binwidth))\n",
    "\n",
    "plt.hist(residuals, color='k', alpha=0.5, bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89237208772342047"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Testing in sample prediction\n",
    "def score_fun(X, y, estimator):\n",
    "    sample_weight = None\n",
    "    return r2_score(y, estimator.predict(X), sample_weight=sample_weight)\n",
    "\n",
    "score_fun(X, y, estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gradient Boosted Regression Tree (GBRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt_params = {\n",
    "            'perc': 0.1\n",
    "            'n_estimators' : 2000,\n",
    "            'n_jobs' : -1\n",
    "        }\n",
    "\n",
    "\n",
    "def gbrt_regressor(gbrt_params):\n",
    "    X_test, y_test, X_train, y_train =  train_test(df, gbrt_params['perc'])\n",
    "    print \"Training points: %s, Testing points: %s\" %(len(y_train), len(y_test))\n",
    "    gbrt_estimator = GradientBoostingRegressor(n_estimators=gb['n_estimators'])\n",
    "    gbrt_estimator.fit(X_train, y_train)\n",
    "    y_estimated = gbrt_estimator.predict(X_test)\n",
    "    score = r2_score(y_test, y_estimated, sample_weight=None)\n",
    "    return score, y_test, y_estimated\n",
    "\n",
    "gbrt_score, gbrt_y_test, gbrt_y_estimated = gbrt_regressor(gbrt_params)\n",
    "gbrt_residuals = gbrt_y_test - gbrt_y_estimated\n",
    "print gbrt_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tree test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '1' '2']\n",
      " ['1' '2' '3']\n",
      " ['0' '3' '2']\n",
      " ['2' '1' '3']]\n",
      "[ 1.   2.5  3.   4. ]\n",
      "[ 1.84333333  2.54        2.56666667  3.11      ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_test = np.asarray([('a',1,2),('b',2,3),('a',3,2),('c',1,3)]) \n",
    "y_test = np.asarray([1,2.5,3,4])\n",
    "\n",
    "# transform 1st column to numbers\n",
    "X_test[:, 0] = LabelEncoder().fit_transform(X_test[:,0]) \n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=150, min_samples_split=1)\n",
    "regressor.fit(X_test, y_test)\n",
    "print X_test\n",
    "print y_test\n",
    "print regressor.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
