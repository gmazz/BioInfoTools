{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import Bio\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section is for table reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "root = os.getcwd()\n",
    "data = root + '/affinity_data.csv'\n",
    "peptide_file = root + '/binding_peptides.fas'\n",
    "HLA_file = root + '/HLA_aln.fas'\n",
    "\n",
    "def to_number(s):\n",
    "    try:\n",
    "        s1 = float(s)\n",
    "        return s1\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional block for data manipulation\n",
    "\n",
    "#data_ref = root+'/affinity_data_refined.csv'\n",
    "#df = df.replace('-', 50000)\n",
    "#res = df.applymap(lambda x: to_number(x))\n",
    "#res['DPB1:04:01'][0]\n",
    "#df.to_csv(data_ref,sep=',', mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data, index_col=0)\n",
    "data_matrix = df.as_matrix()\n",
    "df.stack().hist(color='k', alpha=0.5, bins=100)\n",
    "plt.show()\n",
    "Y_dist_tmp = [i for i in list(data_matrix.flatten().astype(int)) if i < 50000]\n",
    "Y_dist = np.array(Y_dist_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e45e78ce2ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#r = stats.poisson(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#r = stats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpylab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "from scipy.stats import expon\n",
    "from scipy.stats import poisson\n",
    "\n",
    "#expon_example = np.random.exponential(scale=50000, size=17000)\n",
    "#measurements = np.where(expon_example >= 50000)[0]\n",
    "\n",
    "stats.probplot(Y_dist, dist=\"norm\", plot=pylab)\n",
    "#r = stats.poisson.rvs(1.5)\n",
    "#r = expon.ppf([0.001, 0.5, 0.999])\n",
    "#r = stats.poisson(2)\n",
    "#r = stats.\n",
    "stats.probplot(Y_dist, dist=r, plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Dict HLA-peptide IC50: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NestedDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        self[key] = type(self)()\n",
    "        return self[key]\n",
    "\n",
    "affinity = NestedDict()     \n",
    "df = pd.read_csv(data, index_col=0)\n",
    "for k,v in df.stack().iteritems():\n",
    "    affinity[k[0]][k[1]] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HQI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from encode_HQI8 import *\n",
    "from Bio import SeqIO\n",
    "import itertools\n",
    "\n",
    "'''\n",
    "#Itertools chaining example: \n",
    "a = [[1,2,3],[4,5,6]]\n",
    "list(itertools.chain(*a))\n",
    "'''\n",
    "\n",
    "def encode_seq(entry):\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    aaindex = list(itertools.chain(*tmp))    \n",
    "    return aaindex\n",
    "\n",
    "# This operation normalize the data \n",
    "def encode_seq_norm(entry, max_vals, min_vals):\n",
    "    delta = max_vals - min_vals\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    vals = list(itertools.chain(*[list((t - min_vals)/delta) for t in tmp]))\n",
    "    return vals\n",
    "    \n",
    "def min_max(entry):\n",
    "    tmp = encode_aaindex_features(entry)\n",
    "    max_vals = np.amax(tmp, axis=0)\n",
    "    min_vals = np.amin(tmp, axis=0)\n",
    "    return max_vals, min_vals\n",
    "\n",
    "#res_1 = encode_seq('MASSSSVLLVVVLFA')\n",
    "#res_2 = encode_seq_norm('MASSSSVLLVVVLFA', max_vals, min_vals)\n",
    "#print res_1\n",
    "#print res_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurizing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(entries):\n",
    "    max_vals, min_vals = min_max('GAVLIPFYWSTCMNQKRHDE')\n",
    "    feature_dict = {}\n",
    "    for e in entries[0:]:\n",
    "        #feature_dict[e.id] = encode_seq(e.seq)                         # Not-normalized data\n",
    "        feature_dict[e.id] = encode_seq_norm(e.seq, max_vals, min_vals) # Normalized data\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peptide features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "peptides = list(SeqIO.parse(peptide_file, 'fasta'))\n",
    "pep_dict = featurize(peptides)\n",
    "#pep_dict\n",
    "\n",
    "rec_test = SeqRecord(Seq(''.join('Q'), IUPAC.protein), id='id')\n",
    "#featurize([rec_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### HLA descriptors' features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "\n",
    "HLAs = list(SeqIO.parse(HLA_file, 'fasta'))\n",
    "HLA_desc = OrderedDict([\n",
    "                        ('b9', 40),\n",
    "                        ('b11', 42),\n",
    "                        ('b13', 44),\n",
    "                        ('b28', 59),\n",
    "                        ('b30', 61),\n",
    "                        ('b37', 68),\n",
    "                        ('b47', 78),\n",
    "                        ('b57', 88),\n",
    "                        ('b60', 91),\n",
    "                        #('b61', 92),\n",
    "                        ('b67', 98),\n",
    "                        ('b70', 101),\n",
    "                        ('b71', 102),\n",
    "                        ('b74', 105),\n",
    "                        ('b78', 109),\n",
    "                        #('b81', 112),\n",
    "                        #('b82', 113),\n",
    "                        ('b85', 116),\n",
    "                    ])\n",
    "\n",
    "def make_SeqRecord(HLAs, HLA_desc):\n",
    "    HLA_list = []\n",
    "    for h in HLAs:\n",
    "        #print h.id, h.seq[HLA_descriptors['b9']], h.seq[HLA_descriptors['b11']], h.seq[HLA_descriptors['b13']]\n",
    "        sele = [h.seq[i] for i in HLA_desc.values()]\n",
    "        #print h.id, ''.join(sele)\n",
    "        record = SeqRecord(Seq(''.join(sele),\n",
    "                   IUPAC.protein),\n",
    "                   id=h.id)\n",
    "        HLA_list.append(record)\n",
    "    return featurize(HLA_list)\n",
    "\n",
    "    \n",
    "HLAs_dict = make_SeqRecord(HLAs, HLA_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining HLA/peptide features with affinity value into new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fo = open('dataset_norm_v2.csv', 'a+')\n",
    "features_len = len(HLA_desc) * len(HQI8_descriptors) + 15 * len(HQI8_descriptors)\n",
    "features_count = ['f'+ str(i) for i in range(1,features_len+1)]\n",
    "header = 'id,peptide,HLA,' + ','.join(str(x) for x in features_count) + ',IC50\\n'\n",
    "fo.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterates over the elements within the 2-level dict\n",
    "i=1\n",
    "for k,v in affinity.iteritems():\n",
    "    for k1,v1 in v.iteritems():\n",
    "        features = list(itertools.chain(*[pep_dict[k], HLAs_dict[k1]]))\n",
    "        #message = k + '\\t' + k1 + '\\t' + ','.join(str(x) for x in features) + '\\t' + str(v1) + '\\n'\n",
    "        #message = k + '_' + k1 + ',' + ','.join(str(x) for x in features) + ',' + str(v1) + '\\n'\n",
    "        message = str(i) + ',' + k + ',' + k1 + ',' +','.join(str(x) for x in features) + ',' + str(v1) + '\\n'\n",
    "        fo.write(message)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data -> X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/dataset_norm_v2.csv', index_col=0)\n",
    "df = df[df.IC50 < 50000]\n",
    "df = df[df.IC50 > 0]\n",
    "X_df = df.drop(['IC50','peptide','HLA'], axis=1)\n",
    "y_df = df['IC50']\n",
    "\n",
    "# We initially transform the data into \n",
    "X = X_df.as_matrix()\n",
    "y = y_df.as_matrix()\n",
    "target_names = X_df.columns.values\n",
    "\n",
    "#X_df.loc[17172]\n",
    "#len(X[2:122])\n",
    "#print len(X), len(y)\n",
    "#df_test.loc[1:30, ['peptide','HLA','f1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#Itertools chaining example: \n",
      "a = [[1,2,3],[4,5,6]]\n",
      "list(itertools.chain(*a))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "n_comp = 250\n",
    "pca = PCA(n_components=n_comp)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "#print('explained variance ratio (first %s components): \\n %s') %(n_comp, str(pca.explained_variance_ratio_))\n",
    "eigenv = pca.explained_variance_ratio_\n",
    "plt.bar (range(len(eigenv)), eigenv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "f_select = sklearn.feature_selection.f_regression(X, y, center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "feat_zip = zip(f_select[1], list(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3), ('d', 4)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,4,3,2]\n",
    "b = ['a','d','c','b']\n",
    "[(x,y) for (y,x) in sorted(zip(a,b))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_select' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e8a582133894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_select\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# AA importance rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_select' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def feat_seed(num):\n",
    "    res = math.floor((num - 0.1)/4) + 1\n",
    "    return int(res)\n",
    "\n",
    "test_dict = {}\n",
    "feat_importance = [(x,y) for (y,x) in sorted(zip(f_select[1],list(target_names)))]\n",
    "feats = [str(feat_seed(int(x[1:]))) for (y,x) in sorted(zip(f_select[1],list(target_names)))] # AA importance rank\n",
    "points = list(reversed(range(1, len(feats)+1)))\n",
    "feat_points = zip(feats, points)\n",
    "\n",
    "feat_points\n",
    "for i in feat_points:\n",
    "    if test_dict[i[0]]:\n",
    "        test_dict[i[0]] = test_dict[i[0]] + i[1]\n",
    "    else:\n",
    "        test_dict[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regression Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84411029386176006"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=10)\n",
    "estimator.fit(X,y)\n",
    "estimator.score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89237208772342047"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def score_fun(X, y, estimator):\n",
    "    sample_weight = None\n",
    "    return r2_score(y, estimator.predict(X), sample_weight=sample_weight)\n",
    "\n",
    "score_fun(X, y, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03552822 -0.0358004  -0.02397521]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "rf = ensemble.RandomForestRegressor(max_features='auto')\n",
    "X_test, y_test = datasets.make_regression(10000, 10)\n",
    "#score = cross_validation.cross_val_score(rf, X_test, y_test)\n",
    "score = cross_validation.cross_val_score(estimator, X, y)\n",
    "\n",
    "print score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tree test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '1' '2']\n",
      " ['1' '2' '3']\n",
      " ['0' '3' '2']\n",
      " ['2' '1' '3']]\n",
      "[ 1.   2.5  3.   4. ]\n",
      "[ 1.84333333  2.54        2.56666667  3.11      ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_test = np.asarray([('a',1,2),('b',2,3),('a',3,2),('c',1,3)]) \n",
    "y_test = np.asarray([1,2.5,3,4])\n",
    "\n",
    "# transform 1st column to numbers\n",
    "X_test[:, 0] = LabelEncoder().fit_transform(X_test[:,0]) \n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=150, min_samples_split=1)\n",
    "regressor.fit(X_test, y_test)\n",
    "print X_test\n",
    "print y_test\n",
    "print regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
